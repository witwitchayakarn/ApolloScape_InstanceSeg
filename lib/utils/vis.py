# Written by Roy Tseng
#
# Based on:
# --------------------------------------------------------
# Copyright (c) 2017-present, Facebook, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##############################################################################


from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

import os
# Use a non-interactive backend
import cv2

import numpy as np
import pycocotools.mask as mask_util

import utils.keypoints as keypoint_utils
from utils.colormap import colormap

#matplotlib.use('Agg')
import matplotlib.pyplot as plt
from matplotlib.patches import Polygon
import json
from pycocotools import mask as maskUtils

from utilities.utils import euler_angles_to_rotation_matrix
plt.rcParams['pdf.fonttype'] = 42  # For editing in Adobe Illustrator

_GRAY = (218, 227, 218)
_GREEN = (18, 127, 15)
_WHITE = (255, 255, 255)


def kp_connections(keypoints):
    kp_lines = [
        [keypoints.index('left_eye'), keypoints.index('right_eye')],
        [keypoints.index('left_eye'), keypoints.index('nose')],
        [keypoints.index('right_eye'), keypoints.index('nose')],
        [keypoints.index('right_eye'), keypoints.index('right_ear')],
        [keypoints.index('left_eye'), keypoints.index('left_ear')],
        [keypoints.index('right_shoulder'), keypoints.index('right_elbow')],
        [keypoints.index('right_elbow'), keypoints.index('right_wrist')],
        [keypoints.index('left_shoulder'), keypoints.index('left_elbow')],
        [keypoints.index('left_elbow'), keypoints.index('left_wrist')],
        [keypoints.index('right_hip'), keypoints.index('right_knee')],
        [keypoints.index('right_knee'), keypoints.index('right_ankle')],
        [keypoints.index('left_hip'), keypoints.index('left_knee')],
        [keypoints.index('left_knee'), keypoints.index('left_ankle')],
        [keypoints.index('right_shoulder'), keypoints.index('left_shoulder')],
        [keypoints.index('right_hip'), keypoints.index('left_hip')],
    ]
    return kp_lines


def convert_from_cls_format(cls_boxes, cls_segms, cls_keyps=None):
    """Convert from the class boxes/segms/keyps format generated by the testing code.
    """
    box_list = [b for b in cls_boxes if len(b) > 0]
    if len(box_list) > 0:
        boxes = np.concatenate(box_list)
    else:
        boxes = None
    if cls_segms is not None:
        segms = [s for slist in cls_segms for s in slist]
    else:
        segms = None
    if cls_keyps is not None:
        keyps = [k for klist in cls_keyps for k in klist]
    else:
        keyps = None
    classes = []
    for j in range(len(cls_boxes)):
        classes += [j] * len(cls_boxes[j])
    return boxes, segms, keyps, classes


def vis_bbox_opencv(img, bbox, thick=1):
    """Visualizes a bounding box."""
    (x0, y0, w, h) = bbox
    x1, y1 = int(x0 + w), int(y0 + h)
    x0, y0 = int(x0), int(y0)
    cv2.rectangle(img, (x0, y0), (x1, y1), _GREEN, thickness=thick)
    return img


def get_class_string(class_index, score, dataset):
    class_text = dataset.classes[class_index] if dataset is not None else \
        'id{:d}'.format(class_index)
    return class_text + ' {:0.2f}'.format(score).lstrip('0')


def vis_one_image(
        im, im_name, output_dir, boxes, segms=None, keypoints=None, thresh=0.9,
        kp_thresh=2, dpi=200, box_alpha=0.0, dataset=None, show_class=False,
        ext='jpg'):
    """Visual debugging of detections."""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    if isinstance(boxes, list):
        boxes, segms, keypoints, classes = convert_from_cls_format(
            boxes, segms, keypoints)

    if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh:
        return

    if segms is not None:
        masks = mask_util.decode(segms)

    color_list = colormap(rgb=True) / 255

    dataset_keypoints, _ = keypoint_utils.get_keypoints()
    kp_lines = kp_connections(dataset_keypoints)
    cmap = plt.get_cmap('rainbow')
    colors = [cmap(i) for i in np.linspace(0, 1, len(kp_lines) + 2)]

    fig = plt.figure(frameon=False)
    fig.set_size_inches(im.shape[1] / dpi, im.shape[0] / dpi)
    ax = plt.Axes(fig, [0., 0., 1., 1.])
    ax.axis('off')
    fig.add_axes(ax)
    ax.imshow(im)

    # Display in largest to smallest order to reduce occlusion
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    sorted_inds = np.argsort(-areas)

    mask_color_id = 0
    # dataset.classes = sorted((list(dataset.eval_cat)))

    for i in sorted_inds:
        bbox = boxes[i, :4]
        score = boxes[i, -1]
        if score < thresh:
            continue

        if hasattr(dataset, 'classes'):
            print(dataset.classes[classes[i]], score)
        else:
            json_id = dataset.contiguous_category_id_to_json_id[classes[i]]
            class_string = dataset.id_map_to_cat[json_id]
            print(class_string, score)
        # show box (off by default, box_alpha=0.0)
        ax.add_patch(plt.Rectangle((bbox[0], bbox[1]),
                                   bbox[2] - bbox[0],
                                   bbox[3] - bbox[1],
                                   fill=False, edgecolor='g',
                                   linewidth=0.5, alpha=box_alpha))

        if show_class:
            ax.text(
                bbox[0], bbox[1] - 2,
                get_class_string(classes[i], score, dataset),
                fontsize=10,
                family='serif',
                bbox=dict(
                    facecolor='g', alpha=0.4, pad=0, edgecolor='none'),
                color='white')

        # show mask
        if segms is not None and len(segms) > i:
            img = np.ones(im.shape)
            color_mask = color_list[mask_color_id % len(color_list), 0:3]
            mask_color_id += 1

            w_ratio = .4
            for c in range(3):
                color_mask[c] = color_mask[c] * (1 - w_ratio) + w_ratio
            for c in range(3):
                img[:, :, c] = color_mask[c]
            e = masks[:, :, i]

            _, contour, hier = cv2.findContours(
                e.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)

            for c in contour:
                polygon = Polygon(
                    c.reshape((-1, 2)),
                    fill=True, facecolor=color_mask,
                    edgecolor='w', linewidth=1.2,
                    alpha=0.5)
                ax.add_patch(polygon)

        # show keypoints
        if keypoints is not None and len(keypoints) > i:
            kps = keypoints[i]
            plt.autoscale(False)
            for l in range(len(kp_lines)):
                i1 = kp_lines[l][0]
                i2 = kp_lines[l][1]
                if kps[2, i1] > kp_thresh and kps[2, i2] > kp_thresh:
                    x = [kps[0, i1], kps[0, i2]]
                    y = [kps[1, i1], kps[1, i2]]
                    line = ax.plot(x, y)
                    plt.setp(line, color=colors[l], linewidth=1.0, alpha=0.7)
                if kps[2, i1] > kp_thresh:
                    ax.plot(
                        kps[0, i1], kps[1, i1], '.', color=colors[l],
                        markersize=3.0, alpha=0.7)
                if kps[2, i2] > kp_thresh:
                    ax.plot(
                        kps[0, i2], kps[1, i2], '.', color=colors[l],
                        markersize=3.0, alpha=0.7)

            # add mid shoulder / mid hip for better visualization
            mid_shoulder = (
                               kps[:2, dataset_keypoints.index('right_shoulder')] +
                               kps[:2, dataset_keypoints.index('left_shoulder')]) / 2.0
            sc_mid_shoulder = np.minimum(
                kps[2, dataset_keypoints.index('right_shoulder')],
                kps[2, dataset_keypoints.index('left_shoulder')])
            mid_hip = (
                          kps[:2, dataset_keypoints.index('right_hip')] +
                          kps[:2, dataset_keypoints.index('left_hip')]) / 2.0
            sc_mid_hip = np.minimum(
                kps[2, dataset_keypoints.index('right_hip')],
                kps[2, dataset_keypoints.index('left_hip')])
            if (sc_mid_shoulder > kp_thresh and
                        kps[2, dataset_keypoints.index('nose')] > kp_thresh):
                x = [mid_shoulder[0], kps[0, dataset_keypoints.index('nose')]]
                y = [mid_shoulder[1], kps[1, dataset_keypoints.index('nose')]]
                line = ax.plot(x, y)
                plt.setp(
                    line, color=colors[len(kp_lines)], linewidth=1.0, alpha=0.7)
            if sc_mid_shoulder > kp_thresh and sc_mid_hip > kp_thresh:
                x = [mid_shoulder[0], mid_hip[0]]
                y = [mid_shoulder[1], mid_hip[1]]
                line = ax.plot(x, y)
                plt.setp(
                    line, color=colors[len(kp_lines) + 1], linewidth=1.0,
                    alpha=0.7)

        output_name = os.path.basename(im_name) + '.' + ext
        fig.savefig(os.path.join(output_dir, '{}'.format(output_name)), dpi=dpi)
        plt.close('all')


def vis_one_image_cvpr2018_wad(
        im, im_name, output_dir, boxes, segms=None, keypoints=None, thresh=0.9,
        dpi=200, box_alpha=0.0, dataset=None, show_class=False, ext='jpg'):
    """Visual debugging of detections."""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    if isinstance(boxes, list):
        boxes, segms, keypoints, classes = convert_from_cls_format(boxes, segms, keypoints)

    if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh:
        return

    if segms is not None:
        masks = mask_util.decode(segms)

    color_list = colormap(rgb=True) / 255

    dataset_keypoints, _ = keypoint_utils.get_keypoints()
    kp_lines = kp_connections(dataset_keypoints)
    cmap = plt.get_cmap('rainbow')
    colors = [cmap(i) for i in np.linspace(0, 1, len(kp_lines) + 2)]

    fig = plt.figure(frameon=False)
    fig.set_size_inches(im.shape[1] / dpi, im.shape[0] / dpi)
    ax = plt.Axes(fig, [0., 0., 1., 1.])
    ax.axis('off')
    fig.add_axes(ax)
    ax.imshow(im)

    # Display in largest to smallest order to reduce occlusion
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    sorted_inds = np.argsort(-areas)
    mask_color_id = 0
    # [35, 38, 36, 39, 40, 34, 33]

    for i in sorted_inds:
        bbox = boxes[i, :4]
        score = boxes[i, -1]
        if score < thresh:
            continue

        json_id = dataset.contiguous_category_id_to_json_id[classes[i]]
        class_string = dataset.id_map_to_cat[json_id]
        print(class_string, score)
        # show box (off by default, box_alpha=0.0)
        ax.add_patch(plt.Rectangle((bbox[0], bbox[1]),
                                   bbox[2] - bbox[0],
                                   bbox[3] - bbox[1],
                                   fill=False, edgecolor='g',
                                   linewidth=0.5, alpha=box_alpha))

        if show_class:
            ax.text(bbox[0], bbox[1] - 2,
                    class_string + ' {:0.2f}'.format(score).lstrip('0'),
                    fontsize=10,
                    family='serif',
                    bbox=dict(facecolor='g', alpha=0.4, pad=0, edgecolor='none'),
                    color='white')

        # show mask
        if segms is not None and len(segms) > i:
            img = np.ones(im.shape)
            color_mask = color_list[mask_color_id % len(color_list), 0:3]
            mask_color_id += 1

            w_ratio = .4
            for c in range(3):
                color_mask[c] = color_mask[c] * (1 - w_ratio) + w_ratio
            for c in range(3):
                img[:, :, c] = color_mask[c]
            e = masks[:, :, i]

            _, contour, hier = cv2.findContours(e.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)

            for c in contour:
                polygon = Polygon(
                    c.reshape((-1, 2)),
                    fill=True, facecolor=color_mask,
                    edgecolor='w', linewidth=1.2,
                    alpha=0.5)
                ax.add_patch(polygon)

    output_name = os.path.basename(im_name) + '.' + ext
    fig.savefig(os.path.join(output_dir, '{}'.format(output_name)), dpi=dpi)
    plt.close('all')


def vis_one_image_eccv2018_car_3d(
        im, im_name, output_dir, boxes,
        car_cls_prob=None, euler_angle=None, trans_pred=None, car_models=None, intrinsic=None,
        segms=None, keypoints=None, thresh=0.9,
        dpi=200, box_alpha=0.0, dataset=None, ext='jpg'):
    """Visual debugging of detections."""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    if isinstance(boxes, list):
        boxes, segms, keypoints, classes = convert_from_cls_format(boxes, segms, keypoints)

    car_cls = np.argmax(car_cls_prob, axis=1)
    if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh:
        return

    if segms is not None:
        masks = mask_util.decode(segms)

    color_list = colormap(rgb=True) / 255
    fig = plt.figure(frameon=False)
    fig.set_size_inches(im.shape[1] / dpi, im.shape[0] / dpi)
    ax = plt.Axes(fig, [0., 0., 1., 1.])
    ax.axis('off')
    fig.add_axes(ax)
    ax.imshow(im)

    # Display in largest to smallest order to reduce occlusion
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    sorted_inds = np.argsort(-areas)
    mask_color_id = 0
    # [35, 38, 36, 39, 40, 34, 33]

    for i in sorted_inds:
        bbox = boxes[i, :4]
        score = boxes[i, -1]

        if score < thresh:
            continue

        json_id = dataset.contiguous_category_id_to_json_id[classes[i]]
        class_string = dataset.id_map_to_cat[json_id]

        # car_cls
        car_cls_i = car_cls[i]
        euler_angle_i = euler_angle[i]
        trans_pred_i = trans_pred[i]
        car_model_i = dataset.unique_car_models[car_cls_i]
        car_model_name_i = dataset.car_id2name[car_model_i]
        if class_string == 'car':
            print("%s: %.4f, car model: %s" % (class_string, score, car_model_name_i.name) +
                  '. quaternion: ' + ", ".join(['{:.3f}'.format(i) for i in euler_angle_i]) +
                  '. Trans: ' + ", ".join(['{:.3f}'.format(i) for i in trans_pred_i]))
        else:
            print(class_string, score)
        # show box (off by default, box_alpha=0.0)
        ax.add_patch(plt.Rectangle((bbox[0], bbox[1]),
                                   bbox[2] - bbox[0],
                                   bbox[3] - bbox[1],
                                   fill=False, edgecolor='g',
                                   linewidth=0.5, alpha=box_alpha))

        if class_string == 'car':
            #vis_string = car_model_name_i.name + '. quaternion: ' + ", ".join(['{:.3f}'.format(i) for i in rot_pred_i]) + '. Trans: ' + ", ".join(['{:.3f}'.format(i) for i in trans_pred_i])
            vis_string = car_model_name_i.name
            ax.text(bbox[0], bbox[1] - 2,
                    vis_string,
                    fontsize=10,
                    family='serif',
                    bbox=dict(facecolor='g', alpha=0.4, pad=0, edgecolor='none'),
                    color='white')

            # Show predicted pos mesh here:
            if trans_pred_i is not None and euler_angle_i is not None:
                #euler_angle = quaternion_to_euler_angle(rot_pred_i)
                pose = np.concatenate((euler_angle_i, trans_pred_i))
                car_name = car_model_name_i.name
                car = car_models[car_name]
                pose = np.array(pose)
                # project 3D points to 2d image plane
                rmat = euler_angles_to_rotation_matrix(pose[:3])
                rvect, _ = cv2.Rodrigues(rmat)
                imgpts, jac = cv2.projectPoints(np.float32(car['vertices']), rvect, pose[3:], intrinsic, distCoeffs=None)
                triangles = np.array(car['faces']-1).astype('int64')
                x = np.squeeze(imgpts[:, :, 1])
                y = np.squeeze(imgpts[:, :, 0])
                triangles = triangles
                color_mask = color_list[mask_color_id % len(color_list), 0:3]
                ax.triplot(y, x, triangles, alpha=0.8, linewidth=1.2, color=color_mask)
        # show mask
        if segms is not None and len(segms) > i:
            img = np.ones(im.shape)
            color_mask = color_list[mask_color_id % len(color_list), 0:3]
            mask_color_id += 1

            w_ratio = .4
            for c in range(3):
                color_mask[c] = color_mask[c] * (1 - w_ratio) + w_ratio
            for c in range(3):
                img[:, :, c] = color_mask[c]
            e = masks[:, :, i]

            _, contour, hier = cv2.findContours(e.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)

            for c in contour:
                polygon = Polygon(
                    c.reshape((-1, 2)),
                    fill=True, facecolor=color_mask,
                    edgecolor='w', linewidth=1.2,
                    alpha=0.2)
                ax.add_patch(polygon)

    output_name = os.path.basename(im_name) + '.' + ext
    fig.savefig(os.path.join(output_dir, '{}'.format(output_name)), dpi=dpi)
    plt.close('all')


def render_car_cv2(pose, car_name, car_models, intrinsic, mesh_color, ax):
    """Render a car instance given pose and car_name
    """
    car = car_models[car_name]
    pose = np.array(pose)
    # project 3D points to 2d image plane
    rmat = euler_angles_to_rotation_matrix(pose[:3])
    rvect, _ = cv2.Rodrigues(rmat)
    imgpts, jac = cv2.projectPoints(np.float32(car['vertices']), rvect, pose[3:], intrinsic, distCoeffs=None)

    for face in car['faces'] - 1:
        pts = np.array([[imgpts[idx, 0, 0], imgpts[idx, 0, 1]] for idx in face], np.int32)
        polygon = Polygon(
            pts.reshape((-1, 2)),
            fill=True, facecolor=mesh_color,
            edgecolor='w', linewidth=1.2,
            alpha=0.5)
        ax.add_patch(polygon)


def write_pose_to_json(im_name, output_dir, boxes, car_cls_prob, euler_angle, trans_pred,
                       segms, dataset, thresh=0.9, ignored_mask_binary=None, iou_ignore_threshold=0.5):
    """
    Write a Json file for submission
    :param im_name:
    :param output_dir:
    :param car_cls_prob:
    :param euler_angle:
    :param trans_pred:
    :param segms:
    :param dataset:
    :return:
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    json_file = os.path.join(output_dir, im_name+'.json')

    if isinstance(boxes, list):
        boxes, segms, keypoints, classes = convert_from_cls_format(boxes, segms)
    if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh:
        return
    car_cls = np.argmax(car_cls_prob, axis=1)

    if segms is not None:
        masks = mask_util.decode(segms)

    # From largest to smallest order
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    sorted_inds = np.argsort(-areas)
    # [35, 38, 36, 39, 40, 34, 33]

    car_list = []
    for i in sorted_inds:
        score = boxes[i, -1]
        if score < thresh:
            continue

        json_id = dataset.contiguous_category_id_to_json_id[classes[i]]
        class_string = dataset.id_map_to_cat[json_id]

        # car_cls
        car_cls_i = car_cls[i]
        box_i = boxes[i, :-1]
        euler_angle_i = euler_angle[i]
        trans_pred_i = trans_pred[i]
        car_model_i = dataset.unique_car_models[car_cls_i]

        if class_string == 'car':
            # filter out by ignored_mask_binary
            car_info = dict()
            car_info["car_id"] = int(car_model_i)
            car_info["box"] = [int(round(x)) for x in box_i]
            car_info["pose"] = [float(x) for x in euler_angle_i] + [float(x) for x in trans_pred_i]
            # We use rectangle area
            car_info["area"] = int(areas[i])
            car_info["score"] = float(score)
            if iou_ignore_threshold:
                masks = np.zeros_like(ignored_mask_binary)
                masks[int(boxes[i][1]):int(boxes[i][3]), int(boxes[i][0]): int(boxes[i][2])] = 1
                iou_mask = masks * ignored_mask_binary
                iou = np.sum(iou_mask) / int(areas[i])
                if iou <= iou_ignore_threshold:
                    car_list.append(car_info)
                else:
                    print('This mask has been ignored')
            else:
                car_list.append(car_info)

    with open(json_file, 'w') as outfile:
        json.dump(car_list, outfile, indent=4)
